{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EU crop map - Benchmarking on the time period for the crops classes\n",
    "## 1) Split by polygones - accuracy per pixels and per polygone\n",
    "## 2) Split by pixels - accuracy per pixels\n",
    "### Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# JEODPP\n",
    "data_path='/eos/jeodpp/data/projects/REFOCUS/data/S1_GS/all-10days/Map_v7/'\n",
    "project_path='/eos/jeodpp/data/projects/REFOCUS/classification/'\n",
    "path_pol = '/eos/jeodpp/data/projects/REFOCUS/data/polygons/v7'\n",
    "results='/eos/jeodpp/data/projects/REFOCUS/classification/'\n",
    "\n",
    "local='/eos/jeodpp/home/users/verheas/data/LUCAS/v7/'\n",
    "\n",
    "#working directory\n",
    "pwd = project_path\n",
    "\n",
    "# !pip install matplotlib --user\n",
    "# !pip install sklearn --user\n",
    "#import \n",
    "import pandas as pd\n",
    "from pandas import Series,DataFrame\n",
    "import csv\n",
    "import numpy as np\n",
    "import time\n",
    "import sklearn\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-f6644e21f13b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#1) load the S1 10 days extracted values in GEE for all polygons\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mpd_lucas\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'S1_point_allV7_10days_10m_1Jan-31Dec_EU_ratio-db.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'level_1'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'level_2'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pd_lucas'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpd_lucas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "## Load the data\n",
    "#1) load the S1 10 days extracted values in GEE for all polygons\n",
    "\n",
    "pd_lucas= pd.read_csv(os.path.join(data_path,'S1_point_allV7_10days_10m_1Jan-31Dec_EU_ratio-db.csv'),dtype={'level_1':int,'level_2':int})\n",
    "print('pd_lucas',pd_lucas.shape)\n",
    "\n",
    "#concatenate all the data in one dataframe\n",
    "#group cropland, grassland and bareland \n",
    "#number of pixels per class\n",
    "print(pd_lucas.level_1.value_counts())\n",
    "print(pd_lucas.level_2.value_counts())\n",
    "pd_lucas.head()\n",
    "\n",
    "#number of pixels per class\n",
    "#pd_lucas.LC1_COD.value_counts()\n",
    "#pd_lucas.head()\n",
    "pd_lucas.columns\n",
    "\n",
    "##############1.2 Load the shapefile with the polygons - useful to split the polygons in training and test dataset for the accuracy ######################\n",
    "# load csv with of the polygons\n",
    "#2)load csv with the polygons for the split test/validation\n",
    "lucas_polygons = pd.read_csv(os.path.join(path_pol,'LUCAS_2018_Copernicus_attributes_cropmap_level1-2.csv'))\n",
    "lucas_polygons.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################Parameters##################################################\n",
    "#classes - stored in a table 'legend-lucas-all'\n",
    "table_class=pd.read_csv(os.path.join(project_path,'table/legend-lucas-all-v7.csv'),dtype=pd.Int64Dtype())\n",
    "\n",
    "classes_L1=list(table_class['classes_L1'].dropna()) \n",
    "classes_L2=list(table_class['classes_L2'].dropna())\n",
    "\n",
    "#level\n",
    "level_1='level_1'\n",
    "level_2='level_2'\n",
    "\n",
    "##################################Parameters##################################################\n",
    "#classes - stored in a table 'legend-lucas-all'\n",
    "table_class=pd.read_csv(os.path.join(project_path,'table/legend-lucas-all-v2.csv'),dtype=pd.Int64Dtype())\n",
    "\n",
    "classes_L1=list(table_class['classes_L1'].dropna())\n",
    "classes_L2=list(table_class['classes_L2'].dropna())\n",
    "\n",
    "#remap classes and selection of classes to map Level 1\n",
    "classes_in_L1 =  list(table_class['classes_all'].dropna())\n",
    "\n",
    "classes_in_L2 = list(table_class['classes_all'].dropna()),\n",
    "\n",
    "#classes affected by biome selection\n",
    "classes_L1_B= list(table_class['classes_L1_B'].dropna())\n",
    "classes_L2_B= list(table_class['classes_L2'].dropna())\n",
    "\n",
    "#Classes non affected by biome selection\n",
    "#Classes from (A) Artificial, (F) Bare lands and (H) Wetlands can be considered in each models - no biome dependent\n",
    "classes_L1_NB=list(table_class['classes_L1_NB'].dropna())\n",
    "classes_L2_NB=[]\n",
    "#summary of the classes used in the classification\n",
    "classes_classif_L1= list(table_class['L1_BIOME'].dropna())\n",
    "classes_classif_L1_simplify=list(table_class['L1_B_harmon'].dropna())\n",
    "\n",
    "#[100,200,520,300,400,600,800]\n",
    "classes_classif_L2=list(table_class['L2_BIOME'].dropna())\n",
    "classes_classif_L2_simplify=list(table_class['L2_B_harmon'].dropna())\n",
    "\n",
    "###################################Choose parameters for this run #############################################\n",
    "#classes for the classification and biome/no biome differentiation if needed\n",
    "classes_B=classes_L2_B\n",
    "print ('classes_B',classes_B)\n",
    "\n",
    "classes_NB=classes_L2_NB\n",
    "print ('classes_NB',classes_NB)\n",
    "\n",
    "#level\n",
    "level=level_2\n",
    "print('level',level)\n",
    "#crop - level 2, from the table we load only the crop type classes\n",
    "classes=classes_L2\n",
    "print('level',classes)\n",
    "\n",
    "###################################Labels of the classes #############################################\n",
    "labels_csv = pd.read_csv(os.path.join(project_path,'table/legend-lucas2.csv'))\n",
    "labels=labels_csv[labels_csv['class'].isin(classes)] # select only the used labels\n",
    "labels_s=labels_csv[labels_csv['class'].isin(classes)] # select only the used labels\n",
    "print(classes)\n",
    "print(labels)\n",
    "print(labels_s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2956889, 117)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2111    261290\n",
      "2161    119697\n",
      "2131     98670\n",
      "2321     63899\n",
      "2132     44216\n",
      "2501     40453\n",
      "2901     35167\n",
      "2141     31956\n",
      "2112     28826\n",
      "2902     28442\n",
      "2151     25021\n",
      "2311     24369\n",
      "2221     22706\n",
      "2401     22440\n",
      "2502     18600\n",
      "2122     17962\n",
      "2181     17686\n",
      "2211     14965\n",
      "2402     11627\n",
      "2121     10863\n",
      "2312     10208\n",
      "2152      8984\n",
      "2301      7600\n",
      "2331      7020\n",
      "2162      5947\n",
      "2191      4625\n",
      "2302      4400\n",
      "2231      4036\n",
      "2142      3259\n",
      "2182      1588\n",
      "2232       884\n",
      "2212       850\n",
      "2171       661\n",
      "2322       553\n",
      "2222       468\n",
      "2172       207\n",
      "2192        99\n",
      "2332        74\n",
      "Name: ClassifB, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "##############################################################\n",
    "#### 2) Prepare the data for the classification ##############\n",
    "##############################################################\n",
    "\n",
    "#############2.1 Select level of work and classes\n",
    "#copy values in a new column 'Classif' that we will use in the rest of the script\n",
    "pd_lucas['Classif']=pd_lucas[level]\n",
    "print(pd_lucas.shape)\n",
    "\n",
    "#add the biome after the class\n",
    "pd_lucas_biome=pd_lucas[pd_lucas.Classif.isin(classes_B)]\n",
    "pd_lucas_nobiome=pd_lucas[pd_lucas.Classif.isin(classes_NB)]\n",
    "\n",
    "pd_lucas_biome['ClassifB']=pd_lucas_biome['Classif'].astype(str) + pd_lucas_biome['stratum'].astype(str)\n",
    "pd_lucas_nobiome['ClassifB']=pd_lucas_nobiome['Classif'].astype(str) + '0'\n",
    "\n",
    "pd_lucas_b=pd_lucas_biome.append(pd_lucas_nobiome)\n",
    "\n",
    "#legend level 1 - create new column and copy values\n",
    "#pd_level1['ClassL1B']=pd_level1[['LC1_COD', 'BIOME_N']].apply(lambda x: ''.join(x.map(str)), axis=1)\n",
    "#pd_level1['ClassL1B']=pd_level1['ClassL1'].astype(str) + pd_level1['BIOME_N'].astype(str)\n",
    "#print(pd_lucas_b.head())\n",
    "print(pd_lucas_b.ClassifB.value_counts())\n",
    "\n",
    "#############2.2 Prepare the dataframe with the pixels extraction\n",
    "\n",
    "lucas_polygons['Classif']=lucas_polygons.level_2\n",
    "\n",
    "#reclassify\n",
    "#lucas_polygons.Classif=lucas_polygons.Classif.replace(classes_in,\n",
    "#                                                        classes_remap)\n",
    "#print(lucas_polygons.shape)\n",
    "#print(lucas_polygons.Classif.value_counts())\n",
    "\n",
    "#select the classes of interest for Level 1\n",
    "#add the biome after the class\n",
    "\n",
    "lucas_polygons_biome=lucas_polygons[lucas_polygons.Classif.isin(classes_B)]\n",
    "lucas_polygons_nobiome=lucas_polygons[lucas_polygons.Classif.isin(classes_NB)]\n",
    "\n",
    "print(lucas_polygons_biome.shape)\n",
    "print(lucas_polygons_biome.Classif.value_counts())\n",
    "print(lucas_polygons_nobiome.shape)\n",
    "print(lucas_polygons_nobiome.Classif.value_counts())\n",
    "\n",
    "lucas_polygons_biome['ClassifB']=lucas_polygons_biome['Classif'].astype(str) + lucas_polygons_biome['stratum'].astype(str)\n",
    "lucas_polygons_nobiome['ClassifB']=lucas_polygons_nobiome['Classif'].astype(str) + '0'\n",
    "print(lucas_polygons_biome.ClassifB.value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters of the benchmarking on the time period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   NAME_indice    NAME_date                         REGEX_indice  \\\n",
      "0        VV-VH   MONTH[1-1]  (((?<![\\w\\d])VH_)|((?<![\\w\\d])VV_))   \n",
      "1        VV-VH   MONTH[1-2]  (((?<![\\w\\d])VH_)|((?<![\\w\\d])VV_))   \n",
      "2        VV-VH   MONTH[1-3]  (((?<![\\w\\d])VH_)|((?<![\\w\\d])VV_))   \n",
      "3        VV-VH   MONTH[1-4]  (((?<![\\w\\d])VH_)|((?<![\\w\\d])VV_))   \n",
      "4        VV-VH   MONTH[1-5]  (((?<![\\w\\d])VH_)|((?<![\\w\\d])VV_))   \n",
      "5        VV-VH   MONTH[1-6]  (((?<![\\w\\d])VH_)|((?<![\\w\\d])VV_))   \n",
      "6        VV-VH   MONTH[1-7]  (((?<![\\w\\d])VH_)|((?<![\\w\\d])VV_))   \n",
      "7        VV-VH   MONTH[1-8]  (((?<![\\w\\d])VH_)|((?<![\\w\\d])VV_))   \n",
      "8        VV-VH   MONTH[1-9]  (((?<![\\w\\d])VH_)|((?<![\\w\\d])VV_))   \n",
      "9        VV-VH  MONTH[1-10]  (((?<![\\w\\d])VH_)|((?<![\\w\\d])VV_))   \n",
      "10       VV-VH  MONTH[1-11]  (((?<![\\w\\d])VH_)|((?<![\\w\\d])VV_))   \n",
      "11       VV-VH  MONTH[1-12]  (((?<![\\w\\d])VH_)|((?<![\\w\\d])VV_))   \n",
      "\n",
      "                 REGEX_time   TEST  month              name  \\\n",
      "0              (20180[1-1])  dates      1   VV-VHMONTH[1-1]   \n",
      "1              (20180[1-2])  dates      2   VV-VHMONTH[1-2]   \n",
      "2              (20180[1-3])  dates      3   VV-VHMONTH[1-3]   \n",
      "3              (20180[1-4])  dates      4   VV-VHMONTH[1-4]   \n",
      "4              (20180[1-5])  dates      5   VV-VHMONTH[1-5]   \n",
      "5              (20180[1-6])  dates      6   VV-VHMONTH[1-6]   \n",
      "6              (20180[1-7])  dates      7   VV-VHMONTH[1-7]   \n",
      "7              (20180[1-8])  dates      8   VV-VHMONTH[1-8]   \n",
      "8              (20180[1-9])  dates      9   VV-VHMONTH[1-9]   \n",
      "9     (20180[1-9]|20181[0])  dates     10  VV-VHMONTH[1-10]   \n",
      "10  (20180[1-9]|20181[0-1])  dates     11  VV-VHMONTH[1-11]   \n",
      "11  (20180[1-9]|20181[0-2])  dates     12  VV-VHMONTH[1-12]   \n",
      "\n",
      "                                                regex  \n",
      "0     (((?<![\\w\\d])VH_)|((?<![\\w\\d])VV_))(20180[1-1])  \n",
      "1     (((?<![\\w\\d])VH_)|((?<![\\w\\d])VV_))(20180[1-2])  \n",
      "2     (((?<![\\w\\d])VH_)|((?<![\\w\\d])VV_))(20180[1-3])  \n",
      "3     (((?<![\\w\\d])VH_)|((?<![\\w\\d])VV_))(20180[1-4])  \n",
      "4     (((?<![\\w\\d])VH_)|((?<![\\w\\d])VV_))(20180[1-5])  \n",
      "5     (((?<![\\w\\d])VH_)|((?<![\\w\\d])VV_))(20180[1-6])  \n",
      "6     (((?<![\\w\\d])VH_)|((?<![\\w\\d])VV_))(20180[1-7])  \n",
      "7     (((?<![\\w\\d])VH_)|((?<![\\w\\d])VV_))(20180[1-8])  \n",
      "8     (((?<![\\w\\d])VH_)|((?<![\\w\\d])VV_))(20180[1-9])  \n",
      "9   (((?<![\\w\\d])VH_)|((?<![\\w\\d])VV_))(20180[1-9]...  \n",
      "10  (((?<![\\w\\d])VH_)|((?<![\\w\\d])VV_))(20180[1-9]...  \n",
      "11  (((?<![\\w\\d])VH_)|((?<![\\w\\d])VV_))(20180[1-9]...  \n"
     ]
    }
   ],
   "source": [
    "parameters = pd.read_csv(os.path.join(project_path,'table/RF-parameters-table-DATE-VV-VH.csv'))\n",
    "parameters['name']=parameters['NAME_indice']+parameters['NAME_date']\n",
    "parameters['regex']=parameters['REGEX_indice']+parameters['REGEX_time']\n",
    "print(parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A) Split on polygons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "manip='DATE-BIOME-STRATIFY-CROP_pol'\n",
    "if not os.path.exists(os.path.join('result',manip)):\n",
    "    os.mkdir(os.path.join('result',manip))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing : DATE-BIOME-STRATIFY-CROP2  VV-VHMONTH[1-1]\n",
      "1\n",
      "211    4210\n",
      "216    2242\n",
      "213    1615\n",
      "232    1096\n",
      "250     860\n",
      "290     629\n",
      "214     528\n",
      "231     462\n",
      "215     433\n",
      "240     424\n",
      "222     396\n",
      "218     297\n",
      "221     285\n",
      "212     198\n",
      "233     154\n",
      "230     141\n",
      "219      86\n",
      "223      75\n",
      "217      11\n",
      "Name: Classif, dtype: int64\n",
      "Accuracy is :35.04\n",
      "Accuracy is :0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/verheas/.local/lib/python3.5/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "213    930\n",
      "290    683\n",
      "211    619\n",
      "250    472\n",
      "212    388\n",
      "240    285\n",
      "231    222\n",
      "215    209\n",
      "216    141\n",
      "230    106\n",
      "214     75\n",
      "218     32\n",
      "221     23\n",
      "223     19\n",
      "232     15\n",
      "222      7\n",
      "219      4\n",
      "217      3\n",
      "Name: Classif, dtype: int64\n",
      "Accuracy is :29.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/verheas/.local/lib/python3.5/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is :0.68\n",
      "Accuracy is :33.92\n",
      "Accuracy is :34.31\n",
      "processing : DATE-BIOME-STRATIFY-CROP2  VV-VHMONTH[1-2]\n",
      "1\n",
      "211    4210\n",
      "216    2242\n",
      "213    1615\n",
      "232    1096\n",
      "250     860\n",
      "290     629\n",
      "214     528\n",
      "231     462\n",
      "215     433\n",
      "240     424\n",
      "222     396\n",
      "218     297\n",
      "221     285\n",
      "212     198\n",
      "233     154\n",
      "230     141\n",
      "219      86\n",
      "223      75\n",
      "217      11\n",
      "Name: Classif, dtype: int64\n",
      "Accuracy is :37.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/verheas/.local/lib/python3.5/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is :0.66\n",
      "2\n",
      "213    930\n",
      "290    683\n",
      "211    619\n",
      "250    472\n",
      "212    388\n",
      "240    285\n",
      "231    222\n",
      "215    209\n",
      "216    141\n",
      "230    106\n",
      "214     75\n",
      "218     32\n",
      "221     23\n",
      "223     19\n",
      "232     15\n",
      "222      7\n",
      "219      4\n",
      "217      3\n",
      "Name: Classif, dtype: int64\n",
      "Accuracy is :33.37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/verheas/.local/lib/python3.5/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is :0.78\n",
      "Accuracy is :36.69\n",
      "Accuracy is :37.41\n",
      "processing : DATE-BIOME-STRATIFY-CROP2  VV-VHMONTH[1-3]\n",
      "1\n",
      "211    4210\n",
      "216    2242\n",
      "213    1615\n",
      "232    1096\n",
      "250     860\n",
      "290     629\n",
      "214     528\n",
      "231     462\n",
      "215     433\n",
      "240     424\n",
      "222     396\n",
      "218     297\n",
      "221     285\n",
      "212     198\n",
      "233     154\n",
      "230     141\n",
      "219      86\n",
      "223      75\n",
      "217      11\n",
      "Name: Classif, dtype: int64\n",
      "Accuracy is :40.13\n",
      "Accuracy is :0.71\n",
      "2\n",
      "213    930\n",
      "290    683\n",
      "211    619\n",
      "250    472\n",
      "212    388\n",
      "240    285\n",
      "231    222\n",
      "215    209\n",
      "216    141\n",
      "230    106\n",
      "214     75\n",
      "218     32\n",
      "221     23\n",
      "223     19\n",
      "232     15\n",
      "222      7\n",
      "219      4\n",
      "217      3\n",
      "Name: Classif, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/verheas/.local/lib/python3.5/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is :35.32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/verheas/.local/lib/python3.5/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is :0.82\n",
      "Accuracy is :39.22\n",
      "Accuracy is :39.78\n",
      "processing : DATE-BIOME-STRATIFY-CROP2  VV-VHMONTH[1-4]\n",
      "1\n",
      "211    4210\n",
      "216    2242\n",
      "213    1615\n",
      "232    1096\n",
      "250     860\n",
      "290     629\n",
      "214     528\n",
      "231     462\n",
      "215     433\n",
      "240     424\n",
      "222     396\n",
      "218     297\n",
      "221     285\n",
      "212     198\n",
      "233     154\n",
      "230     141\n",
      "219      86\n",
      "223      75\n",
      "217      11\n",
      "Name: Classif, dtype: int64\n",
      "Accuracy is :48.67\n",
      "Accuracy is :0.86\n",
      "2\n",
      "213    930\n",
      "290    683\n",
      "211    619\n",
      "250    472\n",
      "212    388\n",
      "240    285\n",
      "231    222\n",
      "215    209\n",
      "216    141\n",
      "230    106\n",
      "214     75\n",
      "218     32\n",
      "221     23\n",
      "223     19\n",
      "232     15\n",
      "222      7\n",
      "219      4\n",
      "217      3\n",
      "Name: Classif, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/verheas/.local/lib/python3.5/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is :41.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/verheas/.local/lib/python3.5/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is :0.98\n",
      "Accuracy is :47.4\n",
      "Accuracy is :48.41\n",
      "processing : DATE-BIOME-STRATIFY-CROP2  VV-VHMONTH[1-5]\n",
      "1\n",
      "211    4210\n",
      "216    2242\n",
      "213    1615\n",
      "232    1096\n",
      "250     860\n",
      "290     629\n",
      "214     528\n",
      "231     462\n",
      "215     433\n",
      "240     424\n",
      "222     396\n",
      "218     297\n",
      "221     285\n",
      "212     198\n",
      "233     154\n",
      "230     141\n",
      "219      86\n",
      "223      75\n",
      "217      11\n",
      "Name: Classif, dtype: int64\n",
      "Accuracy is :58.39\n",
      "Accuracy is :1.04\n",
      "2\n",
      "213    930\n",
      "290    683\n",
      "211    619\n",
      "250    472\n",
      "212    388\n",
      "240    285\n",
      "231    222\n",
      "215    209\n",
      "216    141\n",
      "230    106\n",
      "214     75\n",
      "218     32\n",
      "221     23\n",
      "223     19\n",
      "232     15\n",
      "222      7\n",
      "219      4\n",
      "217      3\n",
      "Name: Classif, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/verheas/.local/lib/python3.5/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is :51.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/verheas/.local/lib/python3.5/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is :1.16\n",
      "Accuracy is :57.11\n",
      "Accuracy is :57.8\n",
      "processing : DATE-BIOME-STRATIFY-CROP2  VV-VHMONTH[1-6]\n",
      "1\n",
      "211    4210\n",
      "216    2242\n",
      "213    1615\n",
      "232    1096\n",
      "250     860\n",
      "290     629\n",
      "214     528\n",
      "231     462\n",
      "215     433\n",
      "240     424\n",
      "222     396\n",
      "218     297\n",
      "221     285\n",
      "212     198\n",
      "233     154\n",
      "230     141\n",
      "219      86\n",
      "223      75\n",
      "217      11\n",
      "Name: Classif, dtype: int64\n",
      "Accuracy is :62.33\n",
      "Accuracy is :1.11\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/verheas/.local/lib/python3.5/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "213    930\n",
      "290    683\n",
      "211    619\n",
      "250    472\n",
      "212    388\n",
      "240    285\n",
      "231    222\n",
      "215    209\n",
      "216    141\n",
      "230    106\n",
      "214     75\n",
      "218     32\n",
      "221     23\n",
      "223     19\n",
      "232     15\n",
      "222      7\n",
      "219      4\n",
      "217      3\n",
      "Name: Classif, dtype: int64\n",
      "Accuracy is :55.33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/verheas/.local/lib/python3.5/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is :1.25\n",
      "Accuracy is :61.01\n",
      "Accuracy is :61.85\n",
      "processing : DATE-BIOME-STRATIFY-CROP2  VV-VHMONTH[1-7]\n",
      "1\n",
      "211    4210\n",
      "216    2242\n",
      "213    1615\n",
      "232    1096\n",
      "250     860\n",
      "290     629\n",
      "214     528\n",
      "231     462\n",
      "215     433\n",
      "240     424\n",
      "222     396\n",
      "218     297\n",
      "221     285\n",
      "212     198\n",
      "233     154\n",
      "230     141\n",
      "219      86\n",
      "223      75\n",
      "217      11\n",
      "Name: Classif, dtype: int64\n",
      "Accuracy is :64.19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/verheas/.local/lib/python3.5/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is :1.15\n",
      "2\n",
      "213    930\n",
      "290    683\n",
      "211    619\n",
      "250    472\n",
      "212    388\n",
      "240    285\n",
      "231    222\n",
      "215    209\n",
      "216    141\n",
      "230    106\n",
      "214     75\n",
      "218     32\n",
      "221     23\n",
      "223     19\n",
      "232     15\n",
      "222      7\n",
      "219      4\n",
      "217      3\n",
      "Name: Classif, dtype: int64\n",
      "Accuracy is :56.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/verheas/.local/lib/python3.5/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is :1.28\n",
      "Accuracy is :62.75\n",
      "Accuracy is :64.03\n",
      "processing : DATE-BIOME-STRATIFY-CROP2  VV-VHMONTH[1-8]\n",
      "1\n",
      "211    4210\n",
      "216    2242\n",
      "213    1615\n",
      "232    1096\n",
      "250     860\n",
      "290     629\n",
      "214     528\n",
      "231     462\n",
      "215     433\n",
      "240     424\n",
      "222     396\n",
      "218     297\n",
      "221     285\n",
      "212     198\n",
      "233     154\n",
      "230     141\n",
      "219      86\n",
      "223      75\n",
      "217      11\n",
      "Name: Classif, dtype: int64\n",
      "Accuracy is :64.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/verheas/.local/lib/python3.5/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is :1.15\n",
      "2\n",
      "213    930\n",
      "290    683\n",
      "211    619\n",
      "250    472\n",
      "212    388\n",
      "240    285\n",
      "231    222\n",
      "215    209\n",
      "216    141\n",
      "230    106\n",
      "214     75\n",
      "218     32\n",
      "221     23\n",
      "223     19\n",
      "232     15\n",
      "222      7\n",
      "219      4\n",
      "217      3\n",
      "Name: Classif, dtype: int64\n",
      "Accuracy is :56.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/verheas/.local/lib/python3.5/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is :1.28\n",
      "Accuracy is :63.31\n",
      "Accuracy is :64.03\n",
      "processing : DATE-BIOME-STRATIFY-CROP2  VV-VHMONTH[1-9]\n",
      "1\n",
      "211    4210\n",
      "216    2242\n",
      "213    1615\n",
      "232    1096\n",
      "250     860\n",
      "290     629\n",
      "214     528\n",
      "231     462\n",
      "215     433\n",
      "240     424\n",
      "222     396\n",
      "218     297\n",
      "221     285\n",
      "212     198\n",
      "233     154\n",
      "230     141\n",
      "219      86\n",
      "223      75\n",
      "217      11\n",
      "Name: Classif, dtype: int64\n",
      "Accuracy is :64.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/verheas/.local/lib/python3.5/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is :1.15\n",
      "2\n",
      "213    930\n",
      "290    683\n",
      "211    619\n",
      "250    472\n",
      "212    388\n",
      "240    285\n",
      "231    222\n",
      "215    209\n",
      "216    141\n",
      "230    106\n",
      "214     75\n",
      "218     32\n",
      "221     23\n",
      "223     19\n",
      "232     15\n",
      "222      7\n",
      "219      4\n",
      "217      3\n",
      "Name: Classif, dtype: int64\n",
      "Accuracy is :57.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/verheas/.local/lib/python3.5/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is :1.3\n",
      "Accuracy is :63.47\n",
      "Accuracy is :64.3\n",
      "processing : DATE-BIOME-STRATIFY-CROP2  VV-VHMONTH[1-10]\n",
      "1\n",
      "211    4210\n",
      "216    2242\n",
      "213    1615\n",
      "232    1096\n",
      "250     860\n",
      "290     629\n",
      "214     528\n",
      "231     462\n",
      "215     433\n",
      "240     424\n",
      "222     396\n",
      "218     297\n",
      "221     285\n",
      "212     198\n",
      "233     154\n",
      "230     141\n",
      "219      86\n",
      "223      75\n",
      "217      11\n",
      "Name: Classif, dtype: int64\n",
      "Accuracy is :65.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/verheas/.local/lib/python3.5/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is :1.16\n",
      "2\n",
      "213    930\n",
      "290    683\n",
      "211    619\n",
      "250    472\n",
      "212    388\n",
      "240    285\n",
      "231    222\n",
      "215    209\n",
      "216    141\n",
      "230    106\n",
      "214     75\n",
      "218     32\n",
      "221     23\n",
      "223     19\n",
      "232     15\n",
      "222      7\n",
      "219      4\n",
      "217      3\n",
      "Name: Classif, dtype: int64\n",
      "Accuracy is :57.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/verheas/.local/lib/python3.5/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is :1.3\n",
      "Accuracy is :63.77\n",
      "Accuracy is :64.49\n",
      "processing : DATE-BIOME-STRATIFY-CROP2  VV-VHMONTH[1-11]\n",
      "1\n",
      "211    4210\n",
      "216    2242\n",
      "213    1615\n",
      "232    1096\n",
      "250     860\n",
      "290     629\n",
      "214     528\n",
      "231     462\n",
      "215     433\n",
      "240     424\n",
      "222     396\n",
      "218     297\n",
      "221     285\n",
      "212     198\n",
      "233     154\n",
      "230     141\n",
      "219      86\n",
      "223      75\n",
      "217      11\n",
      "Name: Classif, dtype: int64\n",
      "Accuracy is :65.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/verheas/.local/lib/python3.5/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is :1.15\n",
      "2\n",
      "213    930\n",
      "290    683\n",
      "211    619\n",
      "250    472\n",
      "212    388\n",
      "240    285\n",
      "231    222\n",
      "215    209\n",
      "216    141\n",
      "230    106\n",
      "214     75\n",
      "218     32\n",
      "221     23\n",
      "223     19\n",
      "232     15\n",
      "222      7\n",
      "219      4\n",
      "217      3\n",
      "Name: Classif, dtype: int64\n",
      "Accuracy is :58.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/verheas/.local/lib/python3.5/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is :1.3\n",
      "Accuracy is :63.87\n",
      "Accuracy is :64.41\n",
      "processing : DATE-BIOME-STRATIFY-CROP2  VV-VHMONTH[1-12]\n",
      "1\n",
      "211    4210\n",
      "216    2242\n",
      "213    1615\n",
      "232    1096\n",
      "250     860\n",
      "290     629\n",
      "214     528\n",
      "231     462\n",
      "215     433\n",
      "240     424\n",
      "222     396\n",
      "218     297\n",
      "221     285\n",
      "212     198\n",
      "233     154\n",
      "230     141\n",
      "219      86\n",
      "223      75\n",
      "217      11\n",
      "Name: Classif, dtype: int64\n",
      "Accuracy is :65.19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/verheas/.local/lib/python3.5/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is :1.15\n",
      "2\n",
      "213    930\n",
      "290    683\n",
      "211    619\n",
      "250    472\n",
      "212    388\n",
      "240    285\n",
      "231    222\n",
      "215    209\n",
      "216    141\n",
      "230    106\n",
      "214     75\n",
      "218     32\n",
      "221     23\n",
      "223     19\n",
      "232     15\n",
      "222      7\n",
      "219      4\n",
      "217      3\n",
      "Name: Classif, dtype: int64\n",
      "Accuracy is :58.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/verheas/.local/lib/python3.5/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is :1.3\n",
      "Accuracy is :63.83\n",
      "Accuracy is :64.41\n"
     ]
    }
   ],
   "source": [
    "#Option when the biomes are separated and put back together\n",
    "for i_test in range(0,len(parameters['name'])):\n",
    "    print('processing : '+manip+'  ' +parameters['name'][i_test])\n",
    "    \n",
    "    #subset by biomes and create another loop for the 4 biomes\n",
    "    #execute the split/train\n",
    "    #join the results and calculate the OA\n",
    "    y_test_s_all=pd.Series([])\n",
    "    y_test_pred_s_all=pd.Series([])\n",
    "    y_test_s_all_pol=pd.Series([])\n",
    "    y_test_pred_s_all_pol=pd.Series([])\n",
    "    \n",
    "    for biome in range(1,3):\n",
    "        print(biome)\n",
    "        # 1 / create a text file for log recording\n",
    "        file = open(os.path.join(local,'result',manip,parameters['name'][i_test]+'_'+str(biome)+'_remap_1_1_Processing_Log.txt'),\"w\") \n",
    "\n",
    "        file.write('Processing summary \\n') \n",
    "        file.write(\"Date and time start: \"+ datetime.now().strftime(\"%d/%m/%Y %H:%M:%S\")+\"\\n\") \n",
    "        file.write(\"Classes : \"+ str(classes)+\"\\n\") \n",
    "        file.write(\"Regex : \"+ str(parameters['regex'][i_test])+\"\\n\") \n",
    "        file.write(\"Name : \"+ str(parameters['name'][i_test])+\"\\n\") \n",
    "    \n",
    "        #select biome on the polygons\n",
    "        lucas_polygons_biome_b=lucas_polygons_biome[lucas_polygons_biome.stratum.isin([biome])]\n",
    "        lucas_polygons_b=lucas_polygons_biome_b.append(lucas_polygons_nobiome)\n",
    "        #drop 2143 as there is only one\n",
    "        #lucas_polygons_b = lucas_polygons_b[lucas_polygons_b.ClassifB != 2143]\n",
    "\n",
    "        #print('dataframe complet',lucas_polygons_b.shape)\n",
    "        #variety of classes per pixels for the selected biome\n",
    "        #print('dataframe complet',pd.value_counts(lucas_polygons_b.Classif,sort=True))\n",
    "        #print('dataframe complet',lucas_polygons_b.head())\n",
    "        print(lucas_polygons_b.Classif.value_counts())\n",
    "\n",
    "        # Subset the polygons\n",
    "        X_featuresP=lucas_polygons_b.filter(items=['POINT_ID','Classif'])\n",
    "        y_classP=lucas_polygons_b['Classif']#.astype(np.float32)\n",
    "        file.write(\"Input DB polygons shape  : \"+ str(X_featuresP.shape)+\"\\n\") \n",
    "        file.write(\"Input DB polygons columns  : \"+ str(list(X_featuresP.columns))+\"\\n\") \n",
    "    \n",
    "        # 1/ Split between test and train\n",
    "        #TO BE DONE ON THE LUCAS POLYGONS\n",
    "        #https://elitedatascience.com/python-machine-learning-tutorial-scikit-learn\n",
    "        X_trainP,X_testP,y_trainP,y_testP  = train_test_split(X_featuresP,y_classP, test_size=0.2,random_state=5,stratify=y_classP)\n",
    "        file.write(\"X_trainP.shape  : \"+ str(X_trainP.shape)+\"\\n\") \n",
    "        file.write(\"X_testP.shape  : \"+ str(X_testP.shape)+\"\\n\")\n",
    "        file.write(\"y_trainP.shape  : \"+ str(y_trainP.shape)+\"\\n\")\n",
    "        file.write(\"y_testP.shape  : \"+ str(y_testP.shape)+\"\\n\")\n",
    "\n",
    "        # 2/select the pixels from the polygons\n",
    "        #and Subset the DB with regex\n",
    "        indexPOINItrain=pd_lucas_b['POINT_ID'].isin(X_trainP['POINT_ID'])\n",
    "        indexPOINItest=pd_lucas_b['POINT_ID'].isin(X_testP['POINT_ID'])\n",
    "        \n",
    "        X_train=pd_lucas_b[indexPOINItrain].filter(regex=parameters['regex'][i_test])\n",
    "        y_train=pd_lucas_b[indexPOINItrain]['Classif']\n",
    "        X_test=pd_lucas_b[indexPOINItest].filter(regex=parameters['regex'][i_test])\n",
    "        y_test=pd_lucas_b[indexPOINItest]['Classif']\n",
    "        \n",
    "        #write\n",
    "        file.write(\"Input DB X_train pixels shape  : \"+ str(X_train.shape)+\"\\n\") \n",
    "        file.write(\"Input DB X_train pixels columns  : \"+ str(list(X_train.columns))+\"\\n\") \n",
    "        \n",
    "        #keep all info to aggregate prediction per polygons\n",
    "        y_train_pol=pd_lucas_b[indexPOINItrain]\n",
    "        y_test_pol=pd_lucas_b[indexPOINItest]\n",
    "\n",
    "       \n",
    "        # 4/ Save the class distribution for training and testing as CSV\n",
    "        #x = pd.DataFrame(y_train.value_counts().rename_axis('class').reset_index(name='counts'))\n",
    "        x = pd.DataFrame({\"count_pol\": y_train_pol.groupby('POINT_ID').apply(max)['Classif'].value_counts(), \"count_pixel\": y_train.value_counts()}).rename_axis('class')\n",
    "        x.to_csv(os.path.join(local,'result',manip,parameters['name'][i_test]+'_'+str(biome)+'_remap_1_2_Training_class_count_polygons.csv'))\n",
    "        #x = pd.DataFrame(y_test.value_counts().rename_axis('class').reset_index(name='counts'))\n",
    "        x = pd.DataFrame({\"count_pol\": y_test_pol.groupby('POINT_ID').apply(max)['Classif'].value_counts(), \"count_pixel\": y_test.value_counts()}).rename_axis('class')\n",
    "        x.to_csv(os.path.join(local,'result',manip,parameters['name'][i_test]+'_'+str(biome)+'_remap_1_3_Testing_class_count_polygons.csv'))\n",
    "\n",
    "\n",
    "        # 5/ Fit the RANDOM PARAMETERS T\n",
    "        t = time.time()    \n",
    "        clf = RandomForestClassifier(bootstrap=0, criterion='gini', max_depth=None, max_features='auto', \n",
    "                                     min_samples_leaf=12, min_samples_split=3, n_estimators=800, n_jobs=40)\n",
    "                                                                                                                                                                                    \n",
    "        clf.fit(X_train, y_train)\n",
    "\n",
    "        training_time=time.time() - t\n",
    "        file = open(os.path.join(local,'result',manip,parameters['name'][i_test]+'_'+str(biome)+'_remap_1_1_Processing_Log.txt'),\"a\") \n",
    "        file.write(\"Elapsed time for training  : \"+ str(round(training_time))+\" sec \\n\")\n",
    "        #file.write(\"Model  : \" +str(clf)+\"\\n\")\n",
    "        file.close()\n",
    "\n",
    "        # 6/ Feature importances as  CSV\n",
    "        x = list(zip(clf.feature_importances_,X_train.columns))\n",
    "        x = pd.DataFrame(x,columns=[\"Importance\",\"Feature_Name\"])\n",
    "        x.to_csv(os.path.join(local,'result',manip,parameters['name'][i_test]+'_'+str(biome)+'_remap_2_Feature_importance.csv') )\n",
    "        \n",
    "        #append the test value in a file for the 4 biomes\n",
    "        # 7/ OA -evaluate accuracy with the test dataset for the unique rf model\n",
    "        #reclassify the classes by biomes to the simple classes \n",
    "        #transform to series to use replace\n",
    "\n",
    "        #Prediction\n",
    "        y_test_pred=clf.predict(X_test)      \n",
    "        y_test_s=pd.Series(y_test, dtype='float')\n",
    "        #y_test_s=y_test_s.replace(classes_classif,classes_classif_simplify)\n",
    "        \n",
    "        y_test_pred_s=pd.Series(y_test_pred, dtype='float')\n",
    "        #y_test_pred_s=y_test_pred_s.replace(classes_classif,classes_classif_simplify)\n",
    "                \n",
    "        #to calculate accuracy, go back to array    \n",
    "        accuracy = 100.0*(y_test_s.array == y_test_pred_s.array).sum()/y_test_s.shape[0]\n",
    "        print('Accuracy is :' + str(round(accuracy,2)))\n",
    "    \n",
    "        #del(file)\n",
    "        file1 = open(os.path.join(local,'result',manip,parameters['name'][i_test]+'biome'+str(biome)+'_1_1_Accuracy.txt'),\"w\") \n",
    "        #file.write(\"Accuracy of the classifier  : \" +str(round(accuracy,2))+\" % \"+\" \\n\")\n",
    "        file1.write(str(accuracy)+\"\\n\") \n",
    "        file1.close()\n",
    "        \n",
    "        # 8/ Classification report\n",
    "        report = classification_report(y_test_s, y_test_pred_s, output_dict=True)\n",
    "        df = pd.DataFrame(report).transpose()\n",
    "        df.to_csv(os.path.join(local,'result',manip,parameters['name'][i_test]+'biome'+str(biome)+'_3_classification_report.csv') )\n",
    "        \n",
    "        # 9 / Extract confusion matrix to CSV - to fix - labels not correct\n",
    "        confusion_mat=confusion_matrix(y_test_s,y_test_pred_s,labels=classes)\n",
    "        confusion_mat_class=pd.DataFrame(confusion_mat,index=classes,columns=classes)\n",
    "        confusion_mat_class.to_csv(os.path.join(local,'result',manip,parameters['name'][i_test]+'biome'+str(biome)+'_4_confusion_matrix_class.csv'))\n",
    "        \n",
    "        #accuracy mode polygon\n",
    "        #apply a majority rule (mode)\n",
    "        #group it with y_test\n",
    "        y_test_results=pd.DataFrame({'POINT_ID':y_test_pol['POINT_ID'],'ref':y_test,'predict':y_test_pred})\n",
    "        y_test_results=y_test_results.groupby(['POINT_ID'])['predict','ref'].agg(lambda x: x.mode()[0])\n",
    "        \n",
    "        #to calculate accuracy, go back to array    \n",
    "        accuracy_pol = 100.0*(y_test_results['ref'].array == y_test_results['predict'].array).sum()/y_test_results.shape[0]\n",
    "        print('Accuracy is :' + str(round(accuracy_pol,2)))\n",
    "        \n",
    "        #del(file)\n",
    "        file1 = open(os.path.join(local,'result',manip,parameters['name'][i_test]+'biome'+str(biome)+'_1_1_Accuracy_pol.txt'),\"w\") \n",
    "        #file.write(\"Accuracy of the classifier  : \" +str(round(accuracy,2))+\" % \"+\" \\n\")\n",
    "        file1.write(str(accuracy_pol)+\"\\n\") \n",
    "        file1.close()\n",
    "        # 8/ Classification report\n",
    "        report = classification_report(y_test_results['ref'],y_test_results['predict'], output_dict=True)\n",
    "        df = pd.DataFrame(report).transpose()\n",
    "        df.to_csv(os.path.join(local,'result',manip,parameters['name'][i_test]+'biome'+str(biome)+'_3_classification_report_pol.csv') )\n",
    "        \n",
    "        # 9 / Extract confusion matrix to CSV - to fix - labels not correct\n",
    "        confusion_mat=confusion_matrix(y_test_results['ref'],y_test_results['predict'],labels=classes)\n",
    "        confusion_mat_class=pd.DataFrame(confusion_mat,index=classes,columns=classes)\n",
    "        confusion_mat_class.to_csv(os.path.join(local,'result',manip,parameters['name'][i_test]+'biome'+str(biome)+'_4_confusion_matrix_class_pol.csv'))\n",
    "        \n",
    "        y_test_s_all=y_test_s_all.append(y_test_s)      \n",
    "        #print(y_test_all)        \n",
    "        y_test_pred_s_all=y_test_pred_s_all.append(y_test_pred_s)\n",
    "        \n",
    "        #pol\n",
    "        y_test_s_all_pol=y_test_s_all_pol.append(y_test_results['ref'])      \n",
    "        #print(y_test_all)        \n",
    "        y_test_pred_s_all_pol=y_test_pred_s_all_pol.append(y_test_results['predict'])\n",
    "        \n",
    "    #to calculate accuracy, go back to array    \n",
    "    accuracy = 100.0*(y_test_s_all.array == y_test_pred_s_all.array).sum()/y_test_s_all.shape[0]\n",
    "    print('Accuracy is :' + str(round(accuracy,2)))\n",
    "   \n",
    "    #del(file)\n",
    "    file1 = open(os.path.join(local,'result',manip,parameters['name'][i_test]+'_regroup_remap_1_1_Accuracy.txt'),\"w\") \n",
    "    #file.write(\"Accuracy of the classifier  : \" +str(round(accuracy,2))+\" % \"+\" \\n\")\n",
    "    file1.write(str(accuracy)+\"\\n\") \n",
    "    file1.close()\n",
    "    \n",
    "    # 8/ Classification report\n",
    "    report = classification_report(y_test_s_all, y_test_pred_s_all, output_dict=True)\n",
    "    df = pd.DataFrame(report).transpose()\n",
    "    df.to_csv(os.path.join(local,'result',manip,parameters['name'][i_test]+'_regroup_remap_3_classification_report.csv') )\n",
    "\n",
    "    # 9 / Extract confusion matrix to CSV - to fix - labels not correct\n",
    "    confusion_mat=confusion_matrix(y_test_s_all,y_test_pred_s_all,labels=classes)\n",
    "    confusion_mat_class=pd.DataFrame(confusion_mat,index=classes,columns=classes)\n",
    "    confusion_mat_class.to_csv(os.path.join(local,'result',manip,parameters['name'][i_test]+'_regroup_remap_4_confusion_matrix_class.csv'))\n",
    "    #confusion_mat_class=pd.DataFrame(confusion_mat,index= list(labels_s['class']),columns=list(labels_s['class']))\n",
    "    #confusion_mat_class.to_csv(os.path.join(local,'result',manip,parameters['name'][i_test]+'_remap_4_confusion_matrix_class.csv') )\n",
    "    #confusion_mat_label=pd.DataFrame(confusion_mat,index= list(labels_s['label']),columns=list(labels_s['label']))\n",
    "    #confusion_mat_label.to_csv(os.path.join(local,'result',manip,parameters['name'][i_test]+'_remap_4_confusion_matrix_label.csv') )\n",
    "\n",
    "    #to calculate accuracy, go back to array    \n",
    "    accuracy_pol = 100.0*(y_test_s_all_pol.array == y_test_pred_s_all_pol.array).sum()/y_test_s_all_pol.shape[0]\n",
    "    print('Accuracy is :' + str(round(accuracy_pol,2)))\n",
    "    \n",
    "    #del(file)\n",
    "    file1 = open(os.path.join(local,'result',manip,parameters['name'][i_test]+'_regroup_remap_1_1_Accuracy_pol.txt'),\"w\") \n",
    "    #file.write(\"Accuracy of the classifier  : \" +str(round(accuracy,2))+\" % \"+\" \\n\")\n",
    "    file1.write(str(accuracy_pol)+\"\\n\") \n",
    "    file1.close()\n",
    "    \n",
    "    # 8/ Classification report\n",
    "    report = classification_report(y_test_s_all_pol, y_test_pred_s_all_pol, output_dict=True)\n",
    "    df = pd.DataFrame(report).transpose()\n",
    "    df.to_csv(os.path.join(local,'result',manip,parameters['name'][i_test]+'_regroup_remap_3_classification_report_pol.csv') )\n",
    "\n",
    "    # 9 / Extract confusion matrix to CSV - to fix - labels not correct\n",
    "    confusion_mat=confusion_matrix(y_test_s_all_pol,y_test_pred_s_all_pol,labels=classes)\n",
    "    confusion_mat_class=pd.DataFrame(confusion_mat,index=classes,columns=classes)\n",
    "    confusion_mat_class.to_csv(os.path.join(local,'result',manip,parameters['name'][i_test]+'_regroup_remap_4_confusion_matrix_class_pol.csv'))\n",
    "    \n",
    "    file = open(os.path.join(local,'result',manip,parameters['name'][i_test]+'_regroup_remap_1_1_Processing_Log.txt'),\"a\") \n",
    "    file.write(\"Date and time end: \"+ datetime.now().strftime(\"%d/%m/%Y %H:%M:%S\")+\"\\n\") \n",
    "    file.close()\n",
    "    \n",
    "    del(df,clf,confusion_mat)#confusion_mat_label,confusion_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B) Split on pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "manip='DATE-BIOME-STRATIFY-CROP_pix'\n",
    "if not os.path.exists(os.path.join('result',manip)):\n",
    "    os.mkdir(os.path.join('result',manip))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing : DATE-BIOME-STRATIFY-CROP_pix  VV-VHMONTH[1-1]\n",
      "1\n",
      "211    4210\n",
      "216    2242\n",
      "213    1615\n",
      "232    1096\n",
      "250     860\n",
      "290     629\n",
      "214     528\n",
      "231     462\n",
      "215     433\n",
      "240     424\n",
      "222     396\n",
      "218     297\n",
      "221     285\n",
      "212     198\n",
      "233     154\n",
      "230     141\n",
      "219      86\n",
      "223      75\n",
      "217      11\n",
      "Name: Classif, dtype: int64\n",
      "Accuracy is :37.83\n",
      "2\n",
      "213    930\n",
      "290    683\n",
      "211    619\n",
      "250    472\n",
      "212    388\n",
      "240    285\n",
      "231    222\n",
      "215    209\n",
      "216    141\n",
      "230    106\n",
      "214     75\n",
      "218     32\n",
      "221     23\n",
      "223     19\n",
      "232     15\n",
      "222      7\n",
      "219      4\n",
      "217      3\n",
      "Name: Classif, dtype: int64\n",
      "Accuracy is :37.82\n",
      "Accuracy is :37.83\n",
      "processing : DATE-BIOME-STRATIFY-CROP_pix  VV-VHMONTH[1-2]\n",
      "1\n",
      "211    4210\n",
      "216    2242\n",
      "213    1615\n",
      "232    1096\n",
      "250     860\n",
      "290     629\n",
      "214     528\n",
      "231     462\n",
      "215     433\n",
      "240     424\n",
      "222     396\n",
      "218     297\n",
      "221     285\n",
      "212     198\n",
      "233     154\n",
      "230     141\n",
      "219      86\n",
      "223      75\n",
      "217      11\n",
      "Name: Classif, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Option when the biomes are separated and put back together\n",
    "for i_test in range(0,len(parameters['name'])):\n",
    "    print('processing : '+manip+'  ' +parameters['name'][i_test])\n",
    "    #lucas_polygons_biome=lucas_polygons_biome[lucas_polygons_biome.ClassifB!='2332']\n",
    "    #lucas_polygons_biome=lucas_polygons_biome[lucas_polygons_biome.ClassifB!='2194']\n",
    "    #lucas_polygons_biome=lucas_polygons_biome[lucas_polygons_biome.ClassifB!='2234']\n",
    "    \n",
    "    #subset by biomes and create another loop for the 4 biomes\n",
    "    #execute the split/train\n",
    "    #join the results and calculate the OA\n",
    "    y_test_s_all=pd.Series([])\n",
    "    y_test_pred_s_all=pd.Series([])\n",
    "\n",
    "    \n",
    "    for biome in range(1,3):\n",
    "        print(biome)\n",
    "        # 1 / create a text file for log recording\n",
    "        file = open(os.path.join(local,'result',manip,parameters['name'][i_test]+'_'+str(biome)+'_remap_1_1_Processing_Log.txt'),\"w\") \n",
    "\n",
    "        file.write('Processing summary \\n') \n",
    "        file.write(\"Date and time start: \"+ datetime.now().strftime(\"%d/%m/%Y %H:%M:%S\")+\"\\n\") \n",
    "        file.write(\"Classes : \"+ str(classes)+\"\\n\") \n",
    "        file.write(\"Regex : \"+ str(parameters['regex'][i_test])+\"\\n\") \n",
    "        file.write(\"Name : \"+ str(parameters['name'][i_test])+\"\\n\") \n",
    "    \n",
    "        #select biome on the polygons\n",
    "        lucas_polygons_biome_b=lucas_polygons_biome[lucas_polygons_biome.stratum.isin([biome])]\n",
    "        lucas_polygons_b=lucas_polygons_biome_b.append(lucas_polygons_nobiome)\n",
    "        #drop 2143 as there is only one\n",
    "        #lucas_polygons_b = lucas_polygons_b[lucas_polygons_b.ClassifB != 2143]\n",
    "\n",
    "        #print('dataframe complet',lucas_polygons_b.shape)\n",
    "        #variety of classes per pixels for the selected biome\n",
    "        #print('dataframe complet',pd.value_counts(lucas_polygons_b.Classif,sort=True))\n",
    "        #print('dataframe complet',lucas_polygons_b.head())\n",
    "        print(lucas_polygons_b.Classif.value_counts())\n",
    "\n",
    "        # Subset the polygons\n",
    "        X_features=pd_lucas_b.filter(regex=parameters['regex'][i_test])\n",
    "        y_class=pd_lucas_b['Classif']#.astype(np.float32)\n",
    "        file.write(\"Input DB pixel shape  : \"+ str(X_features.shape)+\"\\n\") \n",
    "        file.write(\"Input DB pixel columns  : \"+ str(list(X_features.columns))+\"\\n\") \n",
    "    \n",
    "        # 1/ Split between test and train\n",
    "        #TO BE DONE ON THE LUCAS POLYGONS\n",
    "        #https://elitedatascience.com/python-machine-learning-tutorial-scikit-learn\n",
    "        X_train,X_test,y_train,y_test  = train_test_split(X_features,y_class, test_size=0.2,random_state=5,stratify=y_class)\n",
    "        \n",
    "        file.write(\"X_train.shape  : \"+ str(X_train.shape)+\"\\n\") \n",
    "        file.write(\"X_test.shape  : \"+ str(X_test.shape)+\"\\n\")\n",
    "        file.write(\"y_train.shape  : \"+ str(y_train.shape)+\"\\n\")\n",
    "        file.write(\"y_test.shape  : \"+ str(y_test.shape)+\"\\n\")\n",
    "\n",
    "        # 2/select the pixels from the polygons\n",
    "        #and Subset the DB with regex\n",
    "              \n",
    "        #write\n",
    "        file.write(\"Input DB X_train pixels shape  : \"+ str(X_train.shape)+\"\\n\") \n",
    "        file.write(\"Input DB X_train pixels columns  : \"+ str(list(X_train.columns))+\"\\n\") \n",
    "        \n",
    "      \n",
    "        # 4/ Save the class distribution for training and testing as CSV\n",
    "        #x = pd.DataFrame(y_train.value_counts().rename_axis('class').reset_index(name='counts'))\n",
    "        x = pd.DataFrame({\"count_pixel\": y_train.value_counts()}).rename_axis('class')\n",
    "        x.to_csv(os.path.join(local,'result',manip,parameters['name'][i_test]+'_'+str(biome)+'_remap_1_2_Training_class_count_pixels.csv'))\n",
    "        #x = pd.DataFrame(y_test.value_counts().rename_axis('class').reset_index(name='counts'))\n",
    "        x = pd.DataFrame({\"count_pixel\": y_test.value_counts()}).rename_axis('class')\n",
    "        x.to_csv(os.path.join(local,'result',manip,parameters['name'][i_test]+'_'+str(biome)+'_remap_1_3_Testing_class_count_pixels.csv'))\n",
    "\n",
    "\n",
    "        # 5/ Fit the RANDOM PARAMETERS T\n",
    "        t = time.time()    \n",
    "        clf = RandomForestClassifier(bootstrap=0, criterion='gini', max_depth=None, max_features='auto', \n",
    "                                     min_samples_leaf=12, min_samples_split=3, n_estimators=800, n_jobs=40)\n",
    "                                                                                                                                                                                    \n",
    "        clf.fit(X_train, y_train)\n",
    "\n",
    "        training_time=time.time() - t\n",
    "        file = open(os.path.join(local,'result',manip,parameters['name'][i_test]+'_'+str(biome)+'_remap_1_1_Processing_Log.txt'),\"a\") \n",
    "        file.write(\"Elapsed time for training  : \"+ str(round(training_time))+\" sec \\n\")\n",
    "        #file.write(\"Model  : \" +str(clf)+\"\\n\")\n",
    "        file.close()\n",
    "\n",
    "        # 6/ Feature importances as  CSV\n",
    "        x = list(zip(clf.feature_importances_,X_train.columns))\n",
    "        x = pd.DataFrame(x,columns=[\"Importance\",\"Feature_Name\"])\n",
    "        x.to_csv(os.path.join(local,'result',manip,parameters['name'][i_test]+'_'+str(biome)+'_remap_2_Feature_importance.csv') )\n",
    "        \n",
    "        #append the test value in a file for the 4 biomes\n",
    "        # 7/ OA -evaluate accuracy with the test dataset for the unique rf model\n",
    "        #reclassify the classes by biomes to the simple classes \n",
    "        #transform to series to use replace\n",
    "\n",
    "        #Prediction\n",
    "        y_test_pred=clf.predict(X_test)      \n",
    "        y_test_s=pd.Series(y_test, dtype='float')\n",
    "        #y_test_s=y_test_s.replace(classes_classif,classes_classif_simplify)\n",
    "        \n",
    "        y_test_pred_s=pd.Series(y_test_pred, dtype='float')\n",
    "        #y_test_pred_s=y_test_pred_s.replace(classes_classif,classes_classif_simplify)\n",
    "                \n",
    "        #to calculate accuracy, go back to array    \n",
    "        accuracy = 100.0*(y_test_s.array == y_test_pred_s.array).sum()/y_test_s.shape[0]\n",
    "        print('Accuracy is :' + str(round(accuracy,2)))\n",
    "    \n",
    "        #del(file)\n",
    "        file1 = open(os.path.join(local,'result',manip,parameters['name'][i_test]+'biome'+str(biome)+'_1_1_Accuracy.txt'),\"w\") \n",
    "        #file.write(\"Accuracy of the classifier  : \" +str(round(accuracy,2))+\" % \"+\" \\n\")\n",
    "        file1.write(str(accuracy)+\"\\n\") \n",
    "        file1.close()\n",
    "        \n",
    "        # 8/ Classification report\n",
    "        report = classification_report(y_test_s, y_test_pred_s, output_dict=True)\n",
    "        df = pd.DataFrame(report).transpose()\n",
    "        df.to_csv(os.path.join(local,'result',manip,parameters['name'][i_test]+'biome'+str(biome)+'_3_classification_report.csv') )\n",
    "        \n",
    "        # 9 / Extract confusion matrix to CSV - to fix - labels not correct\n",
    "        confusion_mat=confusion_matrix(y_test_s,y_test_pred_s,labels=classes)\n",
    "        confusion_mat_class=pd.DataFrame(confusion_mat,index=classes,columns=classes)\n",
    "        confusion_mat_class.to_csv(os.path.join(local,'result',manip,parameters['name'][i_test]+'biome'+str(biome)+'_4_confusion_matrix_class.csv'))\n",
    "        \n",
    "        \n",
    "        y_test_s_all=y_test_s_all.append(y_test_s)      \n",
    "        #print(y_test_all)        \n",
    "        y_test_pred_s_all=y_test_pred_s_all.append(y_test_pred_s)\n",
    "    \n",
    "        \n",
    "    #to calculate accuracy, go back to array    \n",
    "    accuracy = 100.0*(y_test_s_all.array == y_test_pred_s_all.array).sum()/y_test_s_all.shape[0]\n",
    "    print('Accuracy is :' + str(round(accuracy,2)))\n",
    "   \n",
    "    #del(file)\n",
    "    file1 = open(os.path.join(local,'result',manip,parameters['name'][i_test]+'_regroup_remap_1_1_Accuracy.txt'),\"w\") \n",
    "    #file.write(\"Accuracy of the classifier  : \" +str(round(accuracy,2))+\" % \"+\" \\n\")\n",
    "    file1.write(str(accuracy)+\"\\n\") \n",
    "    file1.close()\n",
    "    \n",
    "    # 8/ Classification report\n",
    "    report = classification_report(y_test_s_all, y_test_pred_s_all, output_dict=True)\n",
    "    df = pd.DataFrame(report).transpose()\n",
    "    df.to_csv(os.path.join(local,'result',manip,parameters['name'][i_test]+'_regroup_remap_3_classification_report.csv') )\n",
    "\n",
    "    # 9 / Extract confusion matrix to CSV - to fix - labels not correct\n",
    "    confusion_mat=confusion_matrix(y_test_s_all,y_test_pred_s_all,labels=classes)\n",
    "    confusion_mat_class=pd.DataFrame(confusion_mat,index=classes,columns=classes)\n",
    "    confusion_mat_class.to_csv(os.path.join(local,'result',manip,parameters['name'][i_test]+'_regroup_remap_4_confusion_matrix_class.csv'))\n",
    "    #confusion_mat_class=pd.DataFrame(confusion_mat,index= list(labels_s['class']),columns=list(labels_s['class']))\n",
    "    #confusion_mat_class.to_csv(os.path.join(local,'result',manip,parameters['name'][i_test]+'_remap_4_confusion_matrix_class.csv') )\n",
    "    #confusion_mat_label=pd.DataFrame(confusion_mat,index= list(labels_s['label']),columns=list(labels_s['label']))\n",
    "    #confusion_mat_label.to_csv(os.path.join(local,'result',manip,parameters['name'][i_test]+'_remap_4_confusion_matrix_label.csv') )\n",
    "\n",
    "    file = open(os.path.join(local,'result',manip,parameters['name'][i_test]+'_regroup_remap_1_1_Processing_Log.txt'),\"a\") \n",
    "    file.write(\"Date and time end: \"+ datetime.now().strftime(\"%d/%m/%Y %H:%M:%S\")+\"\\n\") \n",
    "    file.close()\n",
    "    \n",
    "    del(df,clf,confusion_mat)#confusion_mat_label,confusion_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
